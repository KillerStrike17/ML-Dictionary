# ML-Dictionary-
This repo contains information of models and keywords used in machine learing

### 1. Feature Visualization 
![Feature Visualization](https://github.com/KillerStrike17/ML-Dictionary-/blob/master/Feature%20Visualization.PNG)

This represents how the image looks like to the neural network. Thus giving an a visual of what the developed network sees. 

### 2. Feature Attribution
![Feature Attribution](https://github.com/KillerStrike17/ML-Dictionary-/blob/master/Feature%20Attribution.PNG)

This studies what part of the image is actually reponsible for the activation of neural network.

### 3. Inceptionism : Going Deeper into Neural Network [3]
Some model Works whereas Others just fail out, reason for this is the input given to the neurons in layer.
The Network first looks into the edges and gradients, then patterns, Parts of Objects, Objects and then Scene and then gives the final decision. 
Each layer of the network deals with features at a different level of abstraction, so the complexity of features we generate depends on which layer we choose to enhance. For example, lower layers tend to produce strokes or simple ornament-like patterns, because those layers are sensitive to basic features such as edges and their orientations.
![Inceptionism 2](https://github.com/KillerStrike17/ML-Dictionary-/blob/master/inceptionism%202.PNG)

This image is developed from the various images shown to the neural network and its learning. 

For example : 

![Inceptionism ](https://github.com/KillerStrike17/ML-Dictionary-/blob/master/inceptionism.PNG)
Here this is to identiy dumbells, but All the training images have muscles in it hence when just dumbells are given to text without muscles, it may identify it incorrectly hence the developer on looking at those images can identify where to make the changes and implement it to get the correct output.


## References
1.

2.

3. https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html
